{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fadhli170402/Data-Mining-/blob/main/hamming_distance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lUTtkbGXOZ9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbec365-4c38-4c6e-c73c-34fd3452ffde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.8/dist-packages (0.8.11)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from python-docx) (4.9.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.8/dist-packages (1.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textract in /usr/local/lib/python3.8/dist-packages (1.6.5)\n",
            "Requirement already satisfied: docx2txt~=0.8 in /usr/local/lib/python3.8/dist-packages (from textract) (0.8)\n",
            "Requirement already satisfied: xlrd~=1.2.0 in /usr/local/lib/python3.8/dist-packages (from textract) (1.2.0)\n",
            "Requirement already satisfied: SpeechRecognition~=3.8.1 in /usr/local/lib/python3.8/dist-packages (from textract) (3.8.1)\n",
            "Requirement already satisfied: python-pptx~=0.6.18 in /usr/local/lib/python3.8/dist-packages (from textract) (0.6.21)\n",
            "Requirement already satisfied: extract-msg<=0.29.* in /usr/local/lib/python3.8/dist-packages (from textract) (0.28.7)\n",
            "Requirement already satisfied: six~=1.12.0 in /usr/local/lib/python3.8/dist-packages (from textract) (1.12.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.8/dist-packages (from textract) (3.0.4)\n",
            "Requirement already satisfied: beautifulsoup4~=4.8.0 in /usr/local/lib/python3.8/dist-packages (from textract) (4.8.2)\n",
            "Requirement already satisfied: pdfminer.six==20191110 in /usr/local/lib/python3.8/dist-packages (from textract) (20191110)\n",
            "Requirement already satisfied: argcomplete~=1.10.0 in /usr/local/lib/python3.8/dist-packages (from textract) (1.10.3)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.8/dist-packages (from pdfminer.six==20191110->textract) (3.16.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.3.2.post1)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.8/dist-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.8/dist-packages (from extract-msg<=0.29.*->textract) (4.2)\n",
            "Requirement already satisfied: compressed-rtf>=1.0.6 in /usr/local/lib/python3.8/dist-packages (from extract-msg<=0.29.*->textract) (1.0.6)\n",
            "Requirement already satisfied: imapclient==2.1.0 in /usr/local/lib/python3.8/dist-packages (from extract-msg<=0.29.*->textract) (2.1.0)\n",
            "Requirement already satisfied: ebcdic>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from extract-msg<=0.29.*->textract) (1.1.1)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.8/dist-packages (from python-pptx~=0.6.18->textract) (7.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from python-pptx~=0.6.18->textract) (4.9.2)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.8/dist-packages (from python-pptx~=0.6.18->textract) (3.0.3)\n",
            "Requirement already satisfied: backports.zoneinfo in /usr/local/lib/python3.8/dist-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (0.2.1)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.8/dist-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.8/dist-packages (from pytz-deprecation-shim->tzlocal>=2.1->extract-msg<=0.29.*->textract) (2022.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx\n",
        "!pip install Sastrawi\n",
        "!pip install textract\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "import string\n",
        "import nltk\n",
        "import textract\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from nltk.probability import FreqDist\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDSGdNbCQ5G1",
        "outputId": "d37486f3-0b86-4bd1-98c3-f08ae42126ee"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membaca dokumen DOCX"
      ],
      "metadata": {
        "id": "FZEXNlt8Rza5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "\n",
        "doc = docx.Document(\"tes 1.docx\")\n",
        "\n",
        "all_parag_doc = doc.paragraphs\n"
      ],
      "metadata": {
        "id": "2g91UOsPR2bK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan DOCX"
      ],
      "metadata": {
        "id": "WiJdxGVKSRGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for parag in all_parag_doc:\n",
        "  print(parag.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8H21P2aSQSA",
        "outputId": "ea38e06c-7c13-4842-d194-883bfd354877"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nama saya syarifah Fathimeh azahra, umur 20 thn, lahir di bundu aceh, sedang mengenyam Pendidikan di itenas bandung, jawa barat. Mengambil mata kuliah data  midning dan information retrieval.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "membuat list "
      ],
      "metadata": {
        "id": "kJme04Q8Tccg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_doc = []\n",
        "for parag in all_parag_doc:\n",
        "  list_doc.append(parag.text)\n",
        "\n",
        "print(list_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bUMXftbTe_P",
        "outputId": "f1fcdf5b-6a34-4969-ad1a-3367b5821839"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Nama saya syarifah Fathimeh azahra, umur 20 thn, lahir di bundu aceh, sedang mengenyam Pendidikan di itenas bandung, jawa barat. Mengambil mata kuliah data  midning dan information retrieval.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_doc = ' '.join(map(str, list_doc))\n",
        "print(text_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wye5afh0ZPUm",
        "outputId": "65b1dd1d-126a-4596-8117-8ad76de106c8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nama saya syarifah Fathimeh azahra, umur 20 thn, lahir di bundu aceh, sedang mengenyam Pendidikan di itenas bandung, jawa barat. Mengambil mata kuliah data  midning dan information retrieval. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = docx.Document(\"tes 2.docx\")\n",
        "all_parag_file1 = file1.paragraphs"
      ],
      "metadata": {
        "id": "-NRMchnCSyX_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for parag in all_parag_file1:\n",
        "  print(parag.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKQSs92qTC84",
        "outputId": "fc1f483f-22e2-4c40-c520-a9ff4bc53540"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nama saya syarifah Fathimah azuhra, umur 20 thn, lahir di bundu aceh, sedang mengenyam Pendidikan di itenas bandung, jawa barat. Mengambil mata kuliah data  midning dan information retrieval.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_file1 = []\n",
        "for parag in all_parag_file1:\n",
        "  list_file1.append(parag.text)\n",
        "\n",
        "print(list_file1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYruXAnZUJkw",
        "outputId": "60690531-2164-40b2-fa56-c6ae66bc5b34"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Nama saya syarifah Fathimah azuhra, umur 20 thn, lahir di bundu aceh, sedang mengenyam Pendidikan di itenas bandung, jawa barat. Mengambil mata kuliah data  midning dan information retrieval.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file1 = ' '.join(map(str, list_file1))\n",
        "print(text_file1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ4sm344ZY2S",
        "outputId": "95ef2c65-d188-4e96-fad9-22f2bc474227"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nama saya syarifah Fathimah azuhra, umur 20 thn, lahir di bundu aceh, sedang mengenyam Pendidikan di itenas bandung, jawa barat. Mengambil mata kuliah data  midning dan information retrieval.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "membaca file PDF"
      ],
      "metadata": {
        "id": "mS9I4kOpURWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwtPTE7gUQrj",
        "outputId": "a411dbc7-df58-41f5-c821-793b34078e9e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.8/dist-packages (2.12.1)\n",
            "Requirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from PyPDF2) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "file2 = open(\"tes 3.pdf\", \"rb\")\n",
        "reader = PyPDF2.PdfFileReader(file2)\n",
        "\n",
        "page = reader.getPage(0)\n",
        "print(page.extractText())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ud5mbLYUZUf",
        "outputId": "13dddec7-d29e-4ad2-a29c-ff9e16f70cc2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nam o saya syarif ih Fathim eh azuhra, umu r 20 thn, lahir di b endu aceh, sedang mengenyam \n",
            "Pendidikan di itenas bandung, jawa barat. Men gambil mata kuliah data  mi dning dan information \n",
            "retrieval.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file2 = page.extractText()\n",
        "print(text_file2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Egjq4e8lVF67",
        "outputId": "94ea142f-23c4-4a8c-ecf4-754f3bc10fb7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nam o saya syarif ih Fathim eh azuhra, umu r 20 thn, lahir di b endu aceh, sedang mengenyam \n",
            "Pendidikan di itenas bandung, jawa barat. Men gambil mata kuliah data  mi dning dan information \n",
            "retrieval.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Processing"
      ],
      "metadata": {
        "id": "zJlu9CcbVwiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "space_doc = text_doc.translate(str.maketrans('','',string.punctuation)).replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\").strip()\n",
        "space_file1 = text_file1.translate(str.maketrans('','',string.punctuation)).replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\").strip()\n",
        "space_file2 = text_file2.translate(str.maketrans('','',string.punctuation)).replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\").strip()\n",
        "\n",
        "space_file2_PDF = text_file2.translate(str.maketrans('','',string.punctuation)).replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\").strip()\n",
        "\n",
        "print(space_doc, '\\n')\n",
        "print(space_file1, '\\n')\n",
        "print(space_file2, '\\n')\n",
        "print(space_file2_PDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo231d0GZIiW",
        "outputId": "6e38b630-a4a4-42b9-da7d-e60caadf9b15"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nama saya syarifah Fathimeh azahra umur 20 thn lahir di bundu aceh sedang mengenyam Pendidikan di itenas bandung jawa barat Mengambil mata kuliah data  midning dan information retrieval \n",
            "\n",
            "Nama saya syarifah Fathimah azuhra umur 20 thn lahir di bundu aceh sedang mengenyam Pendidikan di itenas bandung jawa barat Mengambil mata kuliah data  midning dan information retrieval \n",
            "\n",
            "Nam o saya syarif ih Fathim eh azuhra umu r 20 thn lahir di b endu aceh sedang mengenyam Pendidikan di itenas bandung jawa barat Men gambil mata kuliah data  mi dning dan information retrieval \n",
            "\n",
            "NamosayasyarifihFathimehazuhraumur20thnlahirdibenduacehsedangmengenyamPendidikandiitenasbandungjawabaratMengambilmatakuliahdatamidningdaninformationretrieval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lowercase"
      ],
      "metadata": {
        "id": "PEdhN6COZkla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_doc = space_doc.lower()\n",
        "low_file1 = space_file1.lower()\n",
        "low_file2 = space_file2.lower()\n",
        "\n",
        "low_file_pdf = space_file2_PDF.lower()\n",
        "\n",
        "print(low_doc, '\\n')\n",
        "print(low_file1, '\\n')\n",
        "print(low_file2, '\\n')\n",
        "print(low_file_pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNr587YmZmMO",
        "outputId": "590ceb9f-4606-4157-d5e9-dd673cc99956"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nama saya syarifah fathimeh azahra umur 20 thn lahir di bundu aceh sedang mengenyam pendidikan di itenas bandung jawa barat mengambil mata kuliah data  midning dan information retrieval \n",
            "\n",
            "nama saya syarifah fathimah azuhra umur 20 thn lahir di bundu aceh sedang mengenyam pendidikan di itenas bandung jawa barat mengambil mata kuliah data  midning dan information retrieval \n",
            "\n",
            "nam o saya syarif ih fathim eh azuhra umu r 20 thn lahir di b endu aceh sedang mengenyam pendidikan di itenas bandung jawa barat men gambil mata kuliah data  mi dning dan information retrieval \n",
            "\n",
            "namosayasyarifihfathimehazuhraumur20thnlahirdibenduacehsedangmengenyampendidikandiitenasbandungjawabaratmengambilmatakuliahdatamidningdaninformationretrieval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing "
      ],
      "metadata": {
        "id": "TBHxfn34accF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_doc = nltk.tokenize.word_tokenize(low_doc)\n",
        "token_file1 = nltk.tokenize.word_tokenize(low_file1)\n",
        "token_file2 = nltk.tokenize.word_tokenize(low_file2)\n",
        "token_file_pdf = nltk.tokenize.word_tokenize(low_file_pdf)\n",
        "\n",
        "print(token_doc,'\\n')\n",
        "print(token_file1,'\\n')\n",
        "print(token_file2,'\\n')\n",
        "print(token_file_pdf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRQja7Jsad2I",
        "outputId": "03a091a3-d505-4aaf-edcc-7f060d8cf771"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nama', 'saya', 'syarifah', 'fathimeh', 'azahra', 'umur', '20', 'thn', 'lahir', 'di', 'bundu', 'aceh', 'sedang', 'mengenyam', 'pendidikan', 'di', 'itenas', 'bandung', 'jawa', 'barat', 'mengambil', 'mata', 'kuliah', 'data', 'midning', 'dan', 'information', 'retrieval'] \n",
            "\n",
            "['nama', 'saya', 'syarifah', 'fathimah', 'azuhra', 'umur', '20', 'thn', 'lahir', 'di', 'bundu', 'aceh', 'sedang', 'mengenyam', 'pendidikan', 'di', 'itenas', 'bandung', 'jawa', 'barat', 'mengambil', 'mata', 'kuliah', 'data', 'midning', 'dan', 'information', 'retrieval'] \n",
            "\n",
            "['nam', 'o', 'saya', 'syarif', 'ih', 'fathim', 'eh', 'azuhra', 'umu', 'r', '20', 'thn', 'lahir', 'di', 'b', 'endu', 'aceh', 'sedang', 'mengenyam', 'pendidikan', 'di', 'itenas', 'bandung', 'jawa', 'barat', 'men', 'gambil', 'mata', 'kuliah', 'data', 'mi', 'dning', 'dan', 'information', 'retrieval'] \n",
            "\n",
            "['namosayasyarifihfathimehazuhraumur20thnlahirdibenduacehsedangmengenyampendidikandiitenasbandungjawabaratmengambilmatakuliahdatamidningdaninformationretrieval']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopword"
      ],
      "metadata": {
        "id": "70ntia92bTw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "listStopword = nltk.corpus.stopwords.words('indonesian')\n",
        "tambahstop = ['o','ih','r','b','men','gambil','mi','dning']\n",
        "listStopword.extend(tambahstop)\n",
        "\n",
        "filter_doc = [words for words in token_doc if not words in listStopword]\n",
        "filter_file1 = [words for words in token_file1 if not words in listStopword] \n",
        "filter_file2 = [words for words in token_file2 if not words in listStopword] \n",
        "filter_file2_PDF = [words for words in token_file_pdf if not words in listStopword] \n",
        "\n",
        "print(filter_doc,'\\n')\n",
        "print(filter_file1,'\\n')\n",
        "print(filter_file2,'\\n')\n",
        "print(filter_file2_PDF)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVdYqFk5bVX_",
        "outputId": "47c373e9-a424-455d-cf64-6b3ea54e982e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nama', 'syarifah', 'fathimeh', 'azahra', 'umur', '20', 'thn', 'lahir', 'bundu', 'aceh', 'mengenyam', 'pendidikan', 'itenas', 'bandung', 'jawa', 'barat', 'mengambil', 'mata', 'kuliah', 'data', 'midning', 'information', 'retrieval'] \n",
            "\n",
            "['nama', 'syarifah', 'fathimah', 'azuhra', 'umur', '20', 'thn', 'lahir', 'bundu', 'aceh', 'mengenyam', 'pendidikan', 'itenas', 'bandung', 'jawa', 'barat', 'mengambil', 'mata', 'kuliah', 'data', 'midning', 'information', 'retrieval'] \n",
            "\n",
            "['nam', 'syarif', 'fathim', 'eh', 'azuhra', 'umu', '20', 'thn', 'lahir', 'endu', 'aceh', 'mengenyam', 'pendidikan', 'itenas', 'bandung', 'jawa', 'barat', 'mata', 'kuliah', 'data', 'information', 'retrieval'] \n",
            "\n",
            "['namosayasyarifihfathimehazuhraumur20thnlahirdibenduacehsedangmengenyampendidikandiitenasbandungjawabaratmengambilmatakuliahdatamidningdaninformationretrieval']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming "
      ],
      "metadata": {
        "id": "fiu-XY1fdul3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = StemmerFactory().create_stemmer()\n",
        "kalimat_1 = ' '.join(map(str, filter_doc))\n",
        "kalimat_2 = ' '.join(map(str, filter_file1))\n",
        "kalimat_3 = ' '.join(map(str, filter_file2))\n",
        "kalimat_pdf = ' '.join(map(str, filter_file2_PDF))\n",
        "\n",
        "stem_doc = stemmer.stem(kalimat_1)\n",
        "stem_file1 =stemmer.stem(kalimat_2)\n",
        "stem_file2 = stemmer.stem(kalimat_3)\n",
        "\n",
        "result_doc = nltk.tokenize.word_tokenize(stem_doc)\n",
        "result_file1 = nltk.tokenize.word_tokenize(stem_file1)\n",
        "result_file2 = nltk.tokenize.word_tokenize(stem_file2)\n",
        "\n",
        "print(result_doc,'\\n')\n",
        "print(result_file1,'\\n')\n",
        "print(result_file2)\n"
      ],
      "metadata": {
        "id": "ihRUtaUodx5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1fcc3a-749b-4a9a-d186-11b139a68b08"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nama', 'syarifah', 'fathimeh', 'azahra', 'umur', '20', 'thn', 'lahir', 'bundu', 'aceh', 'kenyam', 'didik', 'itenas', 'bandung', 'jawa', 'barat', 'ambil', 'mata', 'kuliah', 'data', 'midning', 'information', 'retrieval'] \n",
            "\n",
            "['nama', 'syarifah', 'fathimah', 'azuhra', 'umur', '20', 'thn', 'lahir', 'bundu', 'aceh', 'kenyam', 'didik', 'itenas', 'bandung', 'jawa', 'barat', 'ambil', 'mata', 'kuliah', 'data', 'midning', 'information', 'retrieval'] \n",
            "\n",
            "['nam', 'syarif', 'fathim', 'eh', 'azuhra', 'umu', '20', 'thn', 'lahir', 'endu', 'aceh', 'kenyam', 'didik', 'itenas', 'bandung', 'jawa', 'barat', 'mata', 'kuliah', 'data', 'information', 'retrieval']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hamming Distance"
      ],
      "metadata": {
        "id": "1pSL2X8Z0sds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import hamming"
      ],
      "metadata": {
        "id": "_123wXCM0veP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hamming_dist = hamming(result_doc, result_file1)* len(result_doc)\n",
        "Hamming_dist_hasil = hamming(result_doc,result_file1)\n",
        "\n",
        "# Hamming_dist2 = hamming(result_doc, result_file2)* len(result_doc)\n",
        "# Hamming_dist_hasil2 = hamming(result_doc, result_file2)\n",
        "\n",
        "print(\" Total Karakter Reference: \", len(result_doc))\n",
        "print(\" Total Karakter Docx 1 : \", len(result_file1))\n",
        "print(\" Total Karakter PDF: \",len(result_file2))\n",
        "print(\"Persen File 1 dan 2: \", Hamming_dist_hasil)\n",
        "# print(\" Persen file 1 dan 2: \", Hamming_dist_hasil2)\n",
        "print(\"Hamming 1 & 2: \", Hamming_dist)\n",
        "# print(\"Hamming 1 & 3\", Hamming_dist2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M67_1fea0-xf",
        "outputId": "0d5b9205-259c-416a-8532-39049b9c4194"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Total Karakter Reference:  23\n",
            " Total Karakter Docx 1 :  23\n",
            " Total Karakter PDF:  22\n",
            "Persen File 1 dan 2:  0.08695652173913043\n",
            "Hamming 1 & 2:  2.0\n"
          ]
        }
      ]
    }
  ]
}